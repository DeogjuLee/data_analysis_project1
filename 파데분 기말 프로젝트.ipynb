{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeogjuLee/data_analysis_project1/blob/main/%ED%8C%8C%EB%8D%B0%EB%B6%84%20%EA%B8%B0%EB%A7%90%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPkTIBCneChv",
        "outputId": "28cbab2c-fd28-44db-e313-06811a8ac438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 1s (8,768 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "# 폰트 설치\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "# 마이너스 기호 문제 해결\n",
        "import matplotlib\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 세션 재시작 할 것!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6K5lXrtetbo",
        "outputId": "3e08c45a-74ff-410e-c5f8-623ea46dfb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "file_path =  \"/content/gdrive/My Drive/2024-1/초파데/초파데팀플/\" #각자 경로에 맞게 수정 필요!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# youtube api를 위해 설치\n",
        "! pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWPXmFzunduz",
        "outputId": "bd9f9182-b380-4873-a3d2-0b0baa56e2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.137.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.24.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x-pVptHahml"
      },
      "source": [
        "# 1️⃣데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2y69-2GdRCc"
      },
      "source": [
        "\n",
        "#### 구글드라이브 공유 링크 또는 캐글 링크를 통해 파일을 다운"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEzKilypdS9g"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade --no-cache-dir gdown\n",
        "# !gdown --folder '1qPbpKiUMvqdFarg_l1kpnhXmsL-QPzY5?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46RopwUP6xSj"
      },
      "source": [
        "#### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "J_y6bZ9ed4kH",
        "outputId": "7282cc56-d08f-4a41-a279-d45e37d24a65"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/2024-1/초파데/초파데팀플/캐글데이터/BR_youtube_trending_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b1ade6a4fb77>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mcountry_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/2024-1/초파데/초파데팀플/캐글데이터/BR_youtube_trending_data.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# 나라 리스트\n",
        "country_list = ['BR','CA','DE','FR','GB','IN','KR','MX','RU','US']\n",
        "# 각 나라의 파일 경로를 저장할 딕셔너리\n",
        "file_paths = {}\n",
        "# country_list에 있는 각 나라의 파일 경로 생성\n",
        "for country in country_list:\n",
        "#    file_paths[country] = f'/content/캐글데이터/{country}_youtube_trending_data.csv'\n",
        "    file_paths[country] = f'/content/gdrive/MyDrive/2024-1/초파데/초파데팀플/캐글데이터/{country}_youtube_trending_data.csv'\n",
        "\n",
        "\n",
        "# 각 나라의 데이터프레임을 저장할 딕셔너리\n",
        "country_dfs = {}\n",
        "# country_list에 있는 각 나라의 파일을 읽어서 데이터프레임 생성\n",
        "for country in country_list:\n",
        "    file_path = file_paths.get(country)\n",
        "    if file_path:\n",
        "        df = pd.read_csv(file_path)\n",
        "        country_dfs[country] = df\n",
        "    else:\n",
        "        print(f\"File path not found for {country}\")\n",
        "\n",
        "# 결과 출력 (예시로 한국의 데이터프레임 출력)\n",
        "country_dfs['KR']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4xCzv1Rd4kK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# 각 나라의 JSON 파일 경로를 저장할 딕셔너리\n",
        "json_file_paths = {}\n",
        "\n",
        "# country_list에 있는 각 나라의 JSON 파일 경로 생성\n",
        "for country in country_list:\n",
        "    json_file_paths[country] = f'/content/gdrive/MyDrive/2024-1/초파데/초파데팀플/캐글데이터/{country}_category_id.json'\n",
        "\n",
        "country_id_title_dict = {}\n",
        "\n",
        "# JSON 파일을 불러와서 데이터 처리\n",
        "for country, file_path in json_file_paths.items():\n",
        "    with open(file_path, \"r\") as json_file:\n",
        "        country_json = json.load(json_file)\n",
        "\n",
        "    # 'id'와 'title' 추출하여 딕셔너리로 저장\n",
        "    country_id_title_dict[country] = {item['id']: item['snippet']['title'] for item in country_json['items']}\n",
        "\n",
        "for i in country_list:\n",
        "    print(i, len(country_id_title_dict[i])) #나라별 카테고리 개수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZqkR1ILd4kL"
      },
      "outputs": [],
      "source": [
        "country_id_title_dict['US'].keys() - country_id_title_dict['KR'].keys()\n",
        "# US에만 있는것은 29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FEhk4ZSd4kM"
      },
      "outputs": [],
      "source": [
        "country_id_title_dict['US']['29']#29은 'Nonprofits & Activism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaE38IdGd4kO"
      },
      "outputs": [],
      "source": [
        "# csv json 병합\n",
        "for i in country_list:\n",
        "    # categoryId를 수치형에서 문자형으로 변환\n",
        "    country_dfs[i] = country_dfs[i].astype({'categoryId':'str'})\n",
        "    # 'id'와 'categoryId'가 일치하는 경우에만 'category' 열을 추가\n",
        "    country_dfs[i]['category'] = country_dfs[i]['categoryId'].map(country_id_title_dict[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwGo-oxd4kS"
      },
      "outputs": [],
      "source": [
        "# # 한국 뿐만 아니라 다른 나라도 category가 없는게 있음\n",
        "# -> US딕셔너리를 한국뿐만 아니라 모든 나라에게 적용 (어차피 29 제외 내용은 같음)\n",
        "for i in country_list:\n",
        "    country_dfs[i].loc[country_dfs[i].category.isnull()==1, 'category'] = 'Nonprofits & Activism'\n",
        "    print (\"\\nMissing values by columns:  \", i, country_dfs[i].isnull().sum())\n",
        "    country_dfs[i].columns\n",
        "\n",
        "#  description(설명란)에 널값은 있지만, 다른 칼럼은 널값 없음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khY76yk7d4kV"
      },
      "outputs": [],
      "source": [
        "# 최종 병합된 결과 확인 : 나라별(행개수, 칼럼개수)\n",
        "for i in country_list:\n",
        "    print(i, country_dfs[i].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mum8ekKOahqi"
      },
      "source": [
        "# 2️⃣ EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEPUBub7uCqr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "warnings.simplefilter(action='ignore',category = RuntimeWarning)\n",
        "pd.set_option('mode.chained_assignment',  None) #모든 경고 끄기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cixTjCvKpEoY"
      },
      "outputs": [],
      "source": [
        "def bar_for_cat(cat_list):\n",
        "    for i in cat_list:\n",
        "        new_df = kr_df.groupby(i).count().iloc[:,:1]\n",
        "        new_df_sorted = new_df.sort_values('video_id',ascending = False)\n",
        "        new_df_sorted_30 = new_df_sorted.head(20)\n",
        "        new_df_sorted_30[i] = new_df_sorted_30.index\n",
        "        new_df_sorted_30\n",
        "\n",
        "        plt.barh(new_df_sorted_30[i], new_df_sorted_30['video_id'])\n",
        "        plt.xlabel('counts')\n",
        "        plt.ylabel(i)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4loqaKTKp27-"
      },
      "outputs": [],
      "source": [
        "kr_df = country_dfs['KR']\n",
        "cat = ['channelTitle','category']\n",
        "bar_for_cat(cat)\n",
        "# 채널명 기준으로 인급동 진입횟수 상위 30개 정렬: 파뿌리, 총몇명, 숏박스 등등의 유튜버\n",
        "# 카테고리 기준으로 인급동 진입횟수 상위 30개 정렬 : Entertainment가 압도적 1위, People&Blog, Music이 그 뒤를 이음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk5VyzYVqEw7"
      },
      "outputs": [],
      "source": [
        "num = ['view_count','likes','dislikes','comment_count']\n",
        "num_kr_df = kr_df.loc[:,num]\n",
        "num_kr_df['likes_rate'] = num_kr_df['likes']/(num_kr_df['likes']+num_kr_df['dislikes'])\n",
        "num = ['view_count','likes','dislikes','comment_count','likes_rate']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(data = num_kr_df.corr(), annot=True, fmt = '.2f', linewidths=5, cmap='Reds')\n",
        "\n",
        "# 조회수랑 댓글수는 높은 상관관계\n",
        "# dislikes 랑 likes는 음의 상관관계가 아님. 오히려 비례함. (싫어요도 어느정도 인지도가 있어야 달릴 수 있듯 '좋아요와 싫어요'는 양의 관계!)\n",
        "# 반면 dislikes와 likes_rate[싫어요/(좋아요+싫어요)]는 음의 상관관계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5PYFSXazSai"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.boxplot((num_kr_df['likes'], num_kr_df['dislikes']))\n",
        "ax.set_xticklabels(('likes','dislikes'))\n",
        "# boxplot을 그리는 게 의미가 없을 정도로 이상치가 많음\n",
        "# likes 가 dislikes 보다 압도적으로 많음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jT_ZeVkdC3B"
      },
      "outputs": [],
      "source": [
        "# 아웃라이어 보이지 않게\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot((num_kr_df['likes'], num_kr_df['dislikes']),showfliers = False)\n",
        "ax.set_xticklabels(('likes','dislikes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzwAoLYWa0xx"
      },
      "source": [
        "# 3️⃣ 사용자 기능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stnRIhxBa5p8"
      },
      "source": [
        "## 🌠기능1 : 카테고리와 분석기간을 입력하면 기간내 상위유튜버 보여주기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA3uDu0xG7Pu"
      },
      "outputs": [],
      "source": [
        "kr_df = []\n",
        "kr_df = country_dfs['KR']\n",
        "kr_df['trending_date'] = pd.to_datetime(kr_df['publishedAt'])\n",
        "kr_df['publishedAt'] = pd.to_datetime(kr_df['trending_date'])\n",
        "\n",
        "# trending_date과 publishedAt를 보면 UTC(협정 세계시를 기준으로 나타낸 것임)\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# UTC 시간대로 해석하여 datetime 형식으로 변환\n",
        "kr_df['trending_date'] = pd.to_datetime(kr_df['trending_date'])\n",
        "kr_df['publishedAt'] = pd.to_datetime(kr_df['publishedAt'])\n",
        "\n",
        "# 한국 시간대로 변환\n",
        "korea_timezone = pytz.timezone('Asia/Seoul')\n",
        "kr_df['trending_date'] = kr_df['trending_date'].dt.tz_convert('UTC').dt.tz_convert(korea_timezone)\n",
        "kr_df['publishedAt'] = kr_df['publishedAt'].dt.tz_convert('UTC').dt.tz_convert(korea_timezone)\n",
        "\n",
        "kr_df['trending_date_ymd'] = kr_df['trending_date'].dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoN3n7fnKA_7"
      },
      "outputs": [],
      "source": [
        "# 카테고리를 입력받으면 해당 카테고리에서 가장 인급동에 많이 올랐던 유튜버 추천\n",
        "\n",
        "def most_frequent_channel_withdates(category, start_date, end_date):\n",
        "    import matplotlib.pyplot as plt\n",
        "    # 입력받은 카테고리에 해당하는 데이터프레임 필터링\n",
        "    category_df = kr_df[kr_df['categoryId'] == category]\n",
        "\n",
        "    # 날짜 범위 설정 후 datetime 형식으로 변환\n",
        "    start_date = pd.to_datetime(start_date, format=\"%Y-%m-%d\").date()\n",
        "    end_date = pd.to_datetime(end_date, format=\"%Y-%m-%d\").date()\n",
        "\n",
        "    # 지정된 날짜 범위로 데이터프레임 슬라이싱\n",
        "    sliced_df = category_df[(category_df['trending_date_ymd'] >= start_date) & (category_df['trending_date_ymd'] <= end_date)]\n",
        "\n",
        "    # 각 채널별 등장 횟수를 세기\n",
        "    channel_counts = sliced_df['channelTitle'].value_counts()\n",
        "\n",
        "    # 각 채널별 평균 등장 횟수 계산\n",
        "    mean_counts = channel_counts.groupby(channel_counts.index).mean()\n",
        "    mean_counts = pd.DataFrame(mean_counts)\n",
        "\n",
        "    # 가장 많이 등장한 상위 10개 채널과 각 평균 인급동 진입횟수\n",
        "    top_10_channels = channel_counts.head(10)\n",
        "    mean_counts_top10 = mean_counts.loc[top_10_channels.index.tolist(),:]\n",
        "    # print(mean_counts_top10)\n",
        "\n",
        "    # 넘파이 활용한 코드\n",
        "    import numpy as np\n",
        "    # Convert to numpy array for further processing\n",
        "    channels = channel_counts.index.to_numpy()\n",
        "    counts = channel_counts.to_numpy()\n",
        "\n",
        "    # Calculate mean counts for each channel (if needed)\n",
        "    mean_counts = np.mean(counts)\n",
        "\n",
        "    # Get top 10 channels\n",
        "    top_10_indices = np.argsort(-counts)[:10]\n",
        "    top_10_channels = channels[top_10_indices]\n",
        "    top_10_counts = counts[top_10_indices]\n",
        "\n",
        "    # # Plot results\n",
        "    # plt.barh(top_10_channels, top_10_counts)\n",
        "    # plt.xlabel('해당 기간 동안 인급동에 오른 횟수')\n",
        "    # plt.show()\n",
        "\n",
        "    # if top_10_channels.size == 0:\n",
        "    #     print('기간이 너무 짧으면 해당 카테고리 유튜버가 인급동에 올라간 경우가 없을 수 있습니다.\\n그래프 출력이 없을 경우 기간을 넉넉하게 3달 이상 잡으시길 추천드립니다')\n",
        "\n",
        "    # 나눔 폰트 설정\n",
        "    plt.rc('font', family='NanumGothic')\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "\n",
        "    plt.barh(mean_counts_top10.index, mean_counts_top10['count'])\n",
        "    plt.xlabel('해당 기간 동안 인급동에 오른 횟수')\n",
        "    plt.show()\n",
        "    print('기간이 너무 짧으면 해당 카테고리 유튜버가 인급동에 올라간 경우가 없을 수 있습니다.\\n그래프 출력이 없을 경우 기간을 넉넉하게 3달 이상 잡으시길 추천드립니다')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWcGkSvKk_gJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def validate_date(date_str):\n",
        "    # 날짜 형식을 검증하는 정규 표현식 패턴\n",
        "    date_pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
        "    if re.match(date_pattern, date_str):\n",
        "        try:\n",
        "            # 날짜 형식이 맞다면 실제로 존재하는 날짜인지 확인\n",
        "            datetime.strptime(date_str, '%Y-%m-%d')\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BHC3KaNKuVo"
      },
      "outputs": [],
      "source": [
        "# 사용자로부터 카테고리와 날짜 입력 받기\n",
        "display(country_id_title_dict['KR']) #카테고리 명세표 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NhhCLPLdsIL"
      },
      "outputs": [],
      "source": [
        "category_input = input(\"분석하고 싶은 카테고리id를 입력해주세요! 한국에서는 위 데이터프레임에 있는 카테고리id만 가능합니다: \")\n",
        "while True:\n",
        "    start_date_input = input('분석 시작날짜를 입력해주세요 (형식:yyyy-mm-dd): ')\n",
        "    if validate_date(start_date_input):\n",
        "        break\n",
        "    else:\n",
        "        print('형식에 맞춰 다시 입력해주세요.')\n",
        "while True:\n",
        "    end_date_input = input('분석 종료날짜를 입력해주세요 (형식:yyyy-mm-dd): ')\n",
        "    if validate_date(end_date_input):\n",
        "        break\n",
        "    else:\n",
        "        print('형식에 맞춰 다시 입력해주세요.')\n",
        "# 함수 호출\n",
        "most_frequent_channel_withdates(category_input,start_date_input,end_date_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8uGRrba5sO"
      },
      "source": [
        "##🌠기능2 : 유튜버의 시간에 따른 조회수 추세"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dyb_4TqncW6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def lowercase(name):\n",
        "    return name.lower()\n",
        "\n",
        "# kr_df는 이미 로드된 데이터프레임이라고 가정합니다.\n",
        "# kr_df = pd.read_csv('your_data.csv')\n",
        "\n",
        "kr_df = []\n",
        "kr_df = country_dfs['KR']\n",
        "kr_df['Search_name'] = kr_df['channelTitle'].apply(lowercase)\n",
        "\n",
        "name = input('궁금한 유튜버를 입력하세요:')\n",
        "\n",
        "while not pd.Series(kr_df['Search_name'].str.contains(name, case=False)).any():\n",
        "    print(\"해당 문자열을 포함하는 행이 없습니다.\")\n",
        "    name = input(\"다시 검색할 문자열을 입력하세요: \")\n",
        "\n",
        "result_df = kr_df[kr_df['Search_name'].str.contains(name, case=False)]\n",
        "result_unique = result_df.drop_duplicates(subset=['Search_name'])\n",
        "select_list = result_unique['channelTitle'].tolist()\n",
        "\n",
        "print(select_list)\n",
        "name = input('위 리스트 중 원하는 유튜버 채널명을 그대로 입력해주세요:')\n",
        "\n",
        "select_df = result_unique[result_unique['Search_name'] == name.lower()]\n",
        "cate_num = int(select_df['categoryId'].iloc[0])\n",
        "\n",
        "kr_df['categoryId'] = kr_df['categoryId'].astype(int)\n",
        "cate_df = kr_df[kr_df['categoryId'] == cate_num]\n",
        "\n",
        "youtubers_df = cate_df.groupby('channelTitle')['view_count'].sum().sort_values(ascending=False)\n",
        "a = youtubers_df.index.tolist()\n",
        "\n",
        "filtered_df = kr_df[kr_df['channelTitle'].isin(a)].copy()\n",
        "filtered_df['publishedAt'] = pd.to_datetime(filtered_df['publishedAt'])\n",
        "filtered_df['year'] = filtered_df['publishedAt'].dt.year\n",
        "filtered_df['month'] = filtered_df['publishedAt'].dt.month\n",
        "\n",
        "monthly_median_views = filtered_df.groupby(['year', 'month'])['view_count'].median().reset_index()\n",
        "monthly_avg_views = filtered_df.groupby(['year', 'month'])['view_count'].mean().reset_index()\n",
        "\n",
        "top_youtuber = youtubers_df.idxmax()\n",
        "top_filtered_df = kr_df[kr_df['channelTitle'] == top_youtuber].copy()\n",
        "top_filtered_df['publishedAt'] = pd.to_datetime(top_filtered_df['publishedAt'])\n",
        "top_filtered_df['year'] = top_filtered_df['publishedAt'].dt.year\n",
        "top_filtered_df['month'] = top_filtered_df['publishedAt'].dt.month\n",
        "\n",
        "top_avg = top_filtered_df.groupby(['year', 'month'])['view_count'].mean().reset_index()\n",
        "\n",
        "name_df = kr_df[kr_df['channelTitle'] == name].copy()\n",
        "name_df['publishedAt'] = pd.to_datetime(name_df['publishedAt'])\n",
        "name_df['year'] = name_df['publishedAt'].dt.year\n",
        "name_df['month'] = name_df['publishedAt'].dt.month\n",
        "name_avg_views = name_df.groupby(['year', 'month'])['view_count'].mean().reset_index()\n",
        "\n",
        "compare_df = name_avg_views\n",
        "for df, suffix in zip([monthly_avg_views, monthly_median_views, top_avg], ['_2', '_3', '_4']):\n",
        "    compare_df = pd.merge(compare_df, df, on=['year', 'month'], how='inner', suffixes=('', suffix))\n",
        "\n",
        "compare_df['date'] = compare_df['year'].astype(str) + '-' + compare_df['month'].astype(str)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(compare_df['date'], compare_df['view_count'], marker='o', color='g', label='검색한 유튜버')\n",
        "#plt.plot(compare_df['date'], compare_df['view_count_2'], marker='o', color='r', label='같은 카테고리 유튜버 조회수의 평균')\n",
        "plt.plot(compare_df['date'], compare_df['view_count_3'], marker='o', color='b', label='같은 카테고리 유튜버 조회수의 중간값')\n",
        "#plt.plot(compare_df['date'], compare_df['view_count_4'], marker='o', color='y', label='같은 카테고리 내 최상위 유튜버')\n",
        "\n",
        "plt.title('같은 카테고리 유튜버 vs 검색한 유튜버', fontsize=16)\n",
        "plt.xlabel('날짜', fontsize=12)\n",
        "plt.ylabel('조회수', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb9QokfPa5vA"
      },
      "source": [
        "##🌠기능3 : 유튜버의 조회수별 싫어요 산점도\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4T2kKwKpemM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "# 파일 경로 지정\n",
        "directory_path = '/content/gdrive/MyDrive/2024-1/초파데/초파데팀플/캐글데이터/'\n",
        "\n",
        "# CSV 파일 열기\n",
        "with open(directory_path + 'KR_youtube_trending_data.csv', 'r', encoding='utf-8') as f:\n",
        "    data = csv.reader(f, delimiter=',')\n",
        "    header = next(data)\n",
        "\n",
        "    view_count = []\n",
        "    dislike = []\n",
        "    total_view_count = 0\n",
        "    total_dislike = 0\n",
        "    channel_name = input(\"채널 입력: \")  # 유튜버 입력\n",
        "\n",
        "    for row in data:\n",
        "        if row[10] != '0' :\n",
        "            total_view_count += int(row[8])\n",
        "            total_dislike += int(row[10])\n",
        "        if row[4] == channel_name:\n",
        "            if row[10] != '0' :\n",
        "                view_count.append(int(row[8]))  # 유튜버에 따른 조회수\n",
        "                dislike.append(int(row[10]))  # 유튜버에 따른 싫어요\n",
        "\n",
        "    # numpy 배열로 변환\n",
        "    view_count = np.array(view_count)\n",
        "    dislike = np.array(dislike)\n",
        "\n",
        "    # 전체 조회수와 싫어요 수의 비율을 계산하여 일차그래프로 표현\n",
        "    dislike_ratio = total_dislike / total_view_count\n",
        "\n",
        "    # x 값 범위 생성\n",
        "    max_view_count = view_count.max()\n",
        "    x_values = np.arange(max_view_count + 1)\n",
        "\n",
        "    # y 값 계산\n",
        "    y_values = dislike_ratio * x_values\n",
        "\n",
        "    # 그래프 그리기 (파란색)\n",
        "    plt.style.use('ggplot')\n",
        "    plt.rc('font', family='NanumBarunGothic')\n",
        "    plt.plot(x_values, y_values, color='blue', label='다른 유튜버의 싫어요 비율')\n",
        "\n",
        "    # 유튜버의 조회수에 따른 싫어요 수 산점도로 표현\n",
        "    plt.scatter(view_count, dislike, color='red', label='유튜버의 조회수에 대한 싫어요')\n",
        "\n",
        "    # 그래프 제목 설정\n",
        "    plt.title(channel_name + ' 조회수/싫어요 비율')\n",
        "\n",
        "    # x축 레이블 설정\n",
        "    plt.xlabel('조회수')\n",
        "\n",
        "    # y축 레이블 설정\n",
        "    plt.ylabel('싫어요')\n",
        "\n",
        "    # 범례 추가\n",
        "    plt.legend()\n",
        "\n",
        "    # 그래프 표시\n",
        "    plt.show()\n",
        "\n",
        "print('''( ≧ᗜ≦ ) 파란색의 그래프는 다른 유튜버의 싫어요 비율로,\n",
        "👍입력한 유튜버의 산점도(빨간색)가 그래프(파란색)보다 낮다면 논란이 없는 유튜버🙆‍♀️,\n",
        "그래프(파란색)보다 높다면 논란이 있는 유튜버🙅‍♀️라고 할 수 있습니다!''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASmETReyb31O"
      },
      "source": [
        "##🌠기능4 : 인급동 오른 동영상수와 그 비율 보여주기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NujnXSc-jzK"
      },
      "outputs": [],
      "source": [
        "# # youtube api를 위해 설치\n",
        "# ! pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VITPXKdL-U2m"
      },
      "outputs": [],
      "source": [
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "# 본인의 api키를 넣기\n",
        "mykey = 'AIzaSyCOCVTY3_Q5iZfO4i2env2XhiT9dabvong' # 현재 조원의 api 키가 들어가 있음\n",
        "youtube = build('youtube','v3',developerKey=mykey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KMmtl8Cs3hK"
      },
      "outputs": [],
      "source": [
        "# 1년동안 올린 비디오 개수 가져오는 함수\n",
        "import os\n",
        "import googleapiclient.discovery\n",
        "from datetime import datetime, timedelta\n",
        "def get_videos_from_channel(channel_id):\n",
        "    # 채널의 'uploads' 재생목록 ID 가져오기\n",
        "    request = youtube.channels().list(\n",
        "        part=\"contentDetails\",\n",
        "        id=channel_id\n",
        "    )\n",
        "    response = request.execute()\n",
        "    uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "    # 모든 비디오 가져오기\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "    one_year_ago = datetime.now() - timedelta(days=365)\n",
        "    while True:\n",
        "        request = youtube.playlistItems().list(\n",
        "            part=\"snippet\",\n",
        "            playlistId=uploads_playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        response = request.execute()\n",
        "        for item in response[\"items\"]:\n",
        "            video_published_at = item[\"snippet\"][\"publishedAt\"]\n",
        "            video_published_at = datetime.strptime(video_published_at, '%Y-%m-%dT%H:%M:%SZ')\n",
        "            if video_published_at > one_year_ago:\n",
        "                videos.append(item)\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "    return videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb9USh2tsxSC"
      },
      "outputs": [],
      "source": [
        "# 1년간의 해당 유튜버 통계 설명하는 함수\n",
        "def get_youtube_channel_stat_video(channel_title):\n",
        "    import pandas as pd; from datetime import datetime, timedelta; import pytz\n",
        "    pd.options.mode.chained_assignment = None\n",
        "\n",
        "    filtered_df = country_dfs['KR'][country_dfs['KR']['channelTitle'] == channel_title]\n",
        "    id1 = filtered_df.iloc[0]['channelId']\n",
        "\n",
        "    filtered_df['publishedAt'] = pd.to_datetime(filtered_df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ', utc=True)\n",
        "    kst = pytz.timezone('Asia/Seoul')\n",
        "    filtered_df['publishedAt'] = filtered_df['publishedAt'].dt.tz_convert(kst)\n",
        "\n",
        "    current_date_kst = datetime.now(kst)\n",
        "    one_year_ago_kst = current_date_kst - timedelta(days=365)\n",
        "    recent_videos = filtered_df[filtered_df['publishedAt'] >= one_year_ago_kst]\n",
        "    trending_recent_videos = recent_videos['video_id'].nunique()\n",
        "    num_recent_videos = len(get_videos_from_channel(id1))\n",
        "\n",
        "    request = youtube.channels().list(\n",
        "        part='statistics',\n",
        "        id=id1\n",
        "    )\n",
        "    response = request.execute()\n",
        "    total_video_count = int(response['items'][0]['statistics']['videoCount'])\n",
        "    unique_video_ids = filtered_df['video_id'].nunique()\n",
        "    ratio1 = (unique_video_ids / total_video_count) * 100\n",
        "    rounded_ratio1 = round(ratio1, 2)\n",
        "    ratio2 = (trending_recent_videos / num_recent_videos) * 100\n",
        "    rounded_ratio2 = round(ratio2, 2)\n",
        "\n",
        "    # return unique_video_ids, total_video_count, f'{rounded_ratio}%', trending_recent_videos, num_recent_videos\n",
        "    report = f'''\n",
        "    유튜버 '{channel_title}'은 계정 개설시점부터 지금까지 {total_video_count}개의 영상을 올렸습니다.\n",
        "    그중 {unique_video_ids}개가 인기급상승 동영상에 올랐으며, 그 비율은 🚩\\033[1m{rounded_ratio1}%\\033[0m입니다.\n",
        "    최근 1년간은 {num_recent_videos}개의 영상을 올렸습니다.\n",
        "    그중 {trending_recent_videos}개가 인기급상승 동영상에 올랐으며, 그 비율은 🚩\\033[1m{rounded_ratio2}%\\033[0m입니다.\n",
        "    '''\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nqwXKdIs0ED"
      },
      "outputs": [],
      "source": [
        "name = input('검색하고픈 유튜버를 입력해주세요! : ')\n",
        "get_youtube_channel_stat_video(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Zv75P1bGk6"
      },
      "source": [
        "##🌠기능5 : 사용자가 입력한 키워드와 관련된 영상 보여주기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOsb7nilbGk7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import csv\n",
        "\n",
        "# 파일 경로 지정\n",
        "directory_path = '/content/gdrive/MyDrive/2024-1/초파데/초파데팀플/캐글데이터/'\n",
        "\n",
        "# CSV 파일 열기\n",
        "f = open(directory_path + 'KR_youtube_trending_data.csv', 'r', encoding='utf-8')\n",
        "data = csv.reader(f, delimiter=',')\n",
        "header = next(data)  # 헤더 읽기\n",
        "\n",
        "def category_keyword_videos(category, word):\n",
        "    unique_rows = []\n",
        "    unique_rows1 = []\n",
        "\n",
        "\n",
        "    for row in data:\n",
        "        if category == row[5] :\n",
        "            if word in row[1] :                 # 단어가 row[1]안에 있다면\n",
        "                if row[1] not in unique_rows1 : # 제목이 unique_rows에 없다면 (중복제거)\n",
        "                    unique_rows1.append(row[1])\n",
        "                    unique_rows.append(row)\n",
        "\n",
        "\n",
        "    for row in unique_rows :\n",
        "        row[8] = int(row[8]) # 조회수 정수값으로 변경\n",
        "\n",
        "\n",
        "    unique_rows.sort(key=lambda x: x[8], reverse=True)     # 조회수로 정렬\n",
        "\n",
        "\n",
        "    # row[1], row[2], row[3] 데이터를 추출\n",
        "    filtered_rows = [[row[4], row[1], row[8]] for row in unique_rows]\n",
        "\n",
        "\n",
        "    # 데이터 프레임 생성\n",
        "    df = pd.DataFrame(filtered_rows, columns=['chennel', 'title', 'view_counts'])\n",
        "\n",
        "\n",
        "    # 결과 출력\n",
        "    display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-ykgwrwbGk7"
      },
      "outputs": [],
      "source": [
        "# 사용자로부터 카테고리 입력 받기\n",
        "display(country_id_title_dict['KR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T26cds_fT7b"
      },
      "outputs": [],
      "source": [
        "category = input('알고싶은 주제의 카테고리의 번호를 입력하시오: ')\n",
        "word = input('알고 싶은 주제(단어)를 입력하시오: ')\n",
        "category_keyword_videos(category, word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpOYBmSSb33J"
      },
      "source": [
        "##🌠기능6 : 나라별로 어떤 카테고리가 인기 많은지 보여주기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6r1I__Pax5C"
      },
      "outputs": [],
      "source": [
        "# 상위 7개만 보여주도록 수정\n",
        "def pop_category_pie(country):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "\n",
        "    # 카테고리별로 개수 세기\n",
        "    y = country_dfs[country]['category'].value_counts()\n",
        "\n",
        "    # 상위 7개 카테고리와 나머지 합계 계산\n",
        "    top_categories = y[:7]\n",
        "    other_sum = y[7:].sum()\n",
        "\n",
        "    # 데이터 준비\n",
        "    labels = list(top_categories.index) + ['etc']\n",
        "    sizes = list(top_categories.values) + [other_sum]\n",
        "\n",
        "    # 첫 번째 조각을 강조 표시 (1위인 카테고리)\n",
        "    exp = [0.1] + [0] * (len(labels) - 1)\n",
        "\n",
        "    # 컬러맵을 사용하여 색상 지정\n",
        "    cmap = plt.get_cmap('Set3')  # 'Set3' 외에도 다양한 컬러맵 사용 가능\n",
        "    colors = cmap(np.linspace(0, 1, len(sizes)))\n",
        "\n",
        "    # 파이차트 그리기\n",
        "    plt.pie(sizes, labels=labels, colors = colors, autopct='%.2f%%', startangle=0, explode=exp,  pctdistance=0.85, labeldistance=1.1) #퍼센트 숫자가 겹치지 않게 distance 옵션추가\n",
        "    plt.title(f'{country}의 카테고리 분포')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy8vg17DuAz5"
      },
      "outputs": [],
      "source": [
        "country_detail = ['브라질','캐나다','독일','프랑스','영국','인도','한국','멕시코','러시아','미국']\n",
        "country = pd.DataFrame(country_list, country_detail, columns = ['나라별 영문 표기'])\n",
        "display(country)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50U21HWgtghM"
      },
      "outputs": [],
      "source": [
        "c = input('검색하고픈 나라의 ⭐영문명⭐을 입력해주세요! : ')\n",
        "pop_category_pie(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu_plbbY8BOD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}